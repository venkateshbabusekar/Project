{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import all the package\n",
    "from urllib.error import HTTPError\n",
    "import configparser\n",
    "from configparser import SafeConfigParser\n",
    "import urllib.request\n",
    "import time\n",
    "import sys, os\n",
    "import logging\n",
    "import json\n",
    "import datetime as dt\n",
    "import glob\n",
    "import urllib.error\n",
    "import csv\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we are find the root of the directory on which the python is running \n",
    "Root_path=os.getcwd()\n",
    "\n",
    "Creating_path1=\"Data\"\n",
    "path_toread_Data = os.path.join(Root_path,Creating_path1) # we are joining the old with new value to form a new path \n",
    "filetype=\"*.csv\"\n",
    "Creating_path_toread_csv=\"Amazon_Spotify_Just_Name_Lowercase_csv\"\n",
    "path_toread_Data2 = os.path.join(path_toread_Data,Creating_path_toread_csv) # we are joining the old with new value to form a new path \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# we are looping thru all the file and reading the data \n",
    "album_name=[]\n",
    "for name in glob.glob(os.path.join(path_toread_Data2,filetype)):# we are using glob to loop thru the file\n",
    "    f = open(name, 'r')\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        album_name.append(row)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#We are defining a fuction to covert the request to json \n",
    "def convert(input):\n",
    "    if isinstance(input, dict):\n",
    "        return {convert(key): convert(value) for key, value in input.items()}\n",
    "    elif isinstance(input, list):\n",
    "        return [convert(element) for element in input]\n",
    "    else:\n",
    "        return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We are getting the data from the API    \n",
    "\n",
    "\n",
    "def getingArticles( query, api_key,path_for_Data1,spofiy_csv_file_for_notin_name,Todaydate):\n",
    "    for i in range (6926,7000):\n",
    "        try:\n",
    "            single_name = album_name[i][0]\n",
    "            single_name_replaced= single_name.replace(\" \",\"+\")\n",
    "            request_string = \"https://api.spotify.com/v1/search?query=\"+single_name_replaced+\"&type=album&offset=0&limit=20\"\n",
    "            \n",
    "            print(request_string)\n",
    "            response = urllib.request.urlopen(request_string)\n",
    "            content = response.read().decode('utf-8').encode('cp850','replace').decode('cp850')  # we are decoding the record and storing it in content \n",
    "            if content:\n",
    "                articles = convert(json.loads(content))\n",
    "                if len(articles[\"albums\"][\"items\"]) >= 1: #we are checking the respose of the file \n",
    "                    docs = articles[\"albums\"][\"items\"]\n",
    "                    single_name = re.sub('\\W+',' ', single_name )\n",
    "                    single_name=single_name[:50]\n",
    "                    file_name = str(single_name)+ \".json\"\n",
    "                    path_name_filename = os.path.join(path_for_Data1,file_name) # we are joining the old with new value to form a new path \n",
    "                    json_file = open(path_name_filename, 'w')\n",
    "                    json_file.write(content)\n",
    "                    json_file.close()\n",
    "                if len(articles[\"albums\"][\"items\"]) == 0:\n",
    "                    with open (spofiy_csv_file_for_notin_name,'a+') as outputfile1:\n",
    "                            outputfile1.write(single_name+\"\\n\")\n",
    "                    \n",
    "            time.sleep(5) \n",
    "        except HTTPError as e:\n",
    "            logging.error(\"HTTPError on page %s on %s (err no. %s: %s) Here's the URL of the call: %s\", page, date, e.code, e.reason, request_string)\n",
    "            if e.code == 404:\n",
    "                print(\"Script hit a snag and got an HTTPError 403. Check your log file for more info.\")\n",
    "                return\n",
    "            if e.code == 429:\n",
    "                print (\"Waiting. You've probably reached an API limit.\")\n",
    "                time.sleep(30) # wait 30 seconds and try again\n",
    "        except: \n",
    "            logging.error(\"Error on %s page %s: %s\", date, file_number, sys.exc_info()[0])\n",
    "            continue    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:26: DeprecationWarning: The SafeConfigParser class has been renamed to ConfigParser in Python 3.2. This alias will be removed in future versions. Use ConfigParser directly instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://api.spotify.com/v1/search?query=it+overtakes+me&type=album&offset=0&limit=20\n",
      "https://api.spotify.com/v1/search?query=osaka+after+dark+(made+in+japan)&type=album&offset=0&limit=20\n",
      "https://api.spotify.com/v1/search?query=dreamcypher&type=album&offset=0&limit=20\n",
      "https://api.spotify.com/v1/search?query=live+almost&type=album&offset=0&limit=20\n",
      "https://api.spotify.com/v1/search?query=it's+only+time&type=album&offset=0&limit=20\n",
      "https://api.spotify.com/v1/search?query=professional+3&type=album&offset=0&limit=20\n",
      "https://api.spotify.com/v1/search?query=hip+hop+is+dead&type=album&offset=0&limit=20\n",
      "https://api.spotify.com/v1/search?query=phantom+limb&type=album&offset=0&limit=20\n",
      "https://api.spotify.com/v1/search?query=skateboards+2+scrapers&type=album&offset=0&limit=20\n",
      "https://api.spotify.com/v1/search?query=rise+to+power&type=album&offset=0&limit=20\n",
      "https://api.spotify.com/v1/search?query=tristeza/poema/canto/images+on+guitar&type=album&offset=0&limit=20\n",
      "https://api.spotify.com/v1/search?query=not+too+late&type=album&offset=0&limit=20\n",
      "https://api.spotify.com/v1/search?query=diamanti&type=album&offset=0&limit=20\n",
      "https://api.spotify.com/v1/search?query=the+best+of+n.w.a:+the+strength+of+street+knowledge&type=album&offset=0&limit=20\n",
      "https://api.spotify.com/v1/search?query=taken+man&type=album&offset=0&limit=20\n",
      "https://api.spotify.com/v1/search?query=if+the+ocean+gets+rough&type=album&offset=0&limit=20\n",
      "https://api.spotify.com/v1/search?query=knights+of+cydonia&type=album&offset=0&limit=20\n",
      "https://api.spotify.com/v1/search?query=traneing+in+(rudy+van+gelder+remaster)&type=album&offset=0&limit=20\n",
      "https://api.spotify.com/v1/search?query=best+kept+secret&type=album&offset=0&limit=20\n",
      "https://api.spotify.com/v1/search?query=can't+go+back&type=album&offset=0&limit=20\n",
      "https://api.spotify.com/v1/search?query=phantom+punch&type=album&offset=0&limit=20\n",
      "https://api.spotify.com/v1/search?query=nested&type=album&offset=0&limit=20\n",
      "https://api.spotify.com/v1/search?query=ultimate+aural+orgasm&type=album&offset=0&limit=20\n",
      "https://api.spotify.com/v1/search?query=hissing+fauna+are+you+the+destroyer&type=album&offset=0&limit=20\n",
      "https://api.spotify.com/v1/search?query=keren+ann&type=album&offset=0&limit=20\n",
      "https://api.spotify.com/v1/search?query=the+sermon+on+exposition+blvd.+[deluxe+limited+edition+---+includes+5.1+sacd+version+and+40+minute+dvd+of+making+the+record]&type=album&offset=0&limit=20\n",
      "https://api.spotify.com/v1/search?query=the+sermon+on+exposition+blvd.+[fold-out+digipak+with+14+page+booklet]&type=album&offset=0&limit=20\n",
      "https://api.spotify.com/v1/search?query=no+promises&type=album&offset=0&limit=20\n",
      "https://api.spotify.com/v1/search?query=meet+julie+miller&type=album&offset=0&limit=20\n",
      "https://api.spotify.com/v1/search?query=hats+off+to+the+buskers&type=album&offset=0&limit=20\n",
      "https://api.spotify.com/v1/search?query=living+well&type=album&offset=0&limit=20\n",
      "https://api.spotify.com/v1/search?query=light+divides&type=album&offset=0&limit=20\n",
      "https://api.spotify.com/v1/search?query=transparent+things&type=album&offset=0&limit=20\n",
      "https://api.spotify.com/v1/search?query=a+tale+of+two+cities&type=album&offset=0&limit=20\n",
      "https://api.spotify.com/v1/search?query=if+looks+could+kill&type=album&offset=0&limit=20\n",
      "https://api.spotify.com/v1/search?query=tones+of+town&type=album&offset=0&limit=20\n",
      "https://api.spotify.com/v1/search?query=two+shoes&type=album&offset=0&limit=20\n",
      "https://api.spotify.com/v1/search?query=heartbeats+&amp;+triggers&type=album&offset=0&limit=20\n",
      "https://api.spotify.com/v1/search?query=translator&type=album&offset=0&limit=20\n",
      "https://api.spotify.com/v1/search?query=evening+of+the+harvest&type=album&offset=0&limit=20\n",
      "https://api.spotify.com/v1/search?query=schizophrenic+circus&type=album&offset=0&limit=20\n",
      "https://api.spotify.com/v1/search?query=no+time+like+now&type=album&offset=0&limit=20\n",
      "https://api.spotify.com/v1/search?query=the+bird+&amp;+the+bee&type=album&offset=0&limit=20\n",
      "https://api.spotify.com/v1/search?query=back+numbers&type=album&offset=0&limit=20\n",
      "https://api.spotify.com/v1/search?query=what+a+beautiful+place&type=album&offset=0&limit=20\n",
      "https://api.spotify.com/v1/search?query=tango+bitter+sweet&type=album&offset=0&limit=20\n",
      "https://api.spotify.com/v1/search?query=tell+someone&type=album&offset=0&limit=20\n",
      "https://api.spotify.com/v1/search?query=samba+nouvelle+vague&type=album&offset=0&limit=20\n",
      "https://api.spotify.com/v1/search?query=le+monde+musical+de+baden+powell&type=album&offset=0&limit=20\n",
      "https://api.spotify.com/v1/search?query=via+brasil+2&type=album&offset=0&limit=20\n",
      "https://api.spotify.com/v1/search?query=last+time+i+saw+him&type=album&offset=0&limit=20\n",
      "https://api.spotify.com/v1/search?query=sex+change&type=album&offset=0&limit=20\n",
      "https://api.spotify.com/v1/search?query=this+too+will+pass&type=album&offset=0&limit=20\n",
      "https://api.spotify.com/v1/search?query=truth+show+(bonus+cd)+(chop)&type=album&offset=0&limit=20\n",
      "https://api.spotify.com/v1/search?query=the+other+woman&type=album&offset=0&limit=20\n",
      "https://api.spotify.com/v1/search?query=all+of+a+sudden+i+miss+everyone&type=album&offset=0&limit=20\n",
      "https://api.spotify.com/v1/search?query=mama+wailer&type=album&offset=0&limit=20\n",
      "https://api.spotify.com/v1/search?query=house+of+rising+sun&type=album&offset=0&limit=20\n",
      "https://api.spotify.com/v1/search?query=higher+ground&type=album&offset=0&limit=20\n",
      "https://api.spotify.com/v1/search?query=evolve&type=album&offset=0&limit=20\n",
      "https://api.spotify.com/v1/search?query=say+no+to+being+cool:+say+yes+to+being+happy&type=album&offset=0&limit=20\n",
      "https://api.spotify.com/v1/search?query=super+hits&type=album&offset=0&limit=20\n",
      "https://api.spotify.com/v1/search?query=in+the+pines&type=album&offset=0&limit=20\n",
      "https://api.spotify.com/v1/search?query=we+all+belong&type=album&offset=0&limit=20\n",
      "https://api.spotify.com/v1/search?query=sammy+davis+jr+sings+just+for+lovers&type=album&offset=0&limit=20\n",
      "https://api.spotify.com/v1/search?query=the+spoiler&type=album&offset=0&limit=20\n",
      "https://api.spotify.com/v1/search?query=you+gotta+take+a+little+love&type=album&offset=0&limit=20\n",
      "https://api.spotify.com/v1/search?query=right+touch&type=album&offset=0&limit=20\n",
      "https://api.spotify.com/v1/search?query=puddle+city+racing+lights&type=album&offset=0&limit=20\n",
      "https://api.spotify.com/v1/search?query=tear+it+down&type=album&offset=0&limit=20\n",
      "https://api.spotify.com/v1/search?query=sylvain+sylvain&type=album&offset=0&limit=20\n",
      "https://api.spotify.com/v1/search?query=runaway+love&type=album&offset=0&limit=20\n",
      "https://api.spotify.com/v1/search?query=en+avant+doute...&type=album&offset=0&limit=20\n",
      "https://api.spotify.com/v1/search?query=alpha&type=album&offset=0&limit=20\n"
     ]
    }
   ],
   "source": [
    "# This is the main function in which u will get the data, it will call the rest of the function \n",
    "def main():\n",
    "    Todaydate=dt.datetime.today().strftime(\"%Y_%m_%d\")\n",
    "\n",
    "    Creating_path2=\"Spotify_Album_Large_json\"\n",
    "    path_for_Data = os.path.join(Root_path,Creating_path1) # we are joining the old with new value to form a new path \n",
    "    if not os.path.exists(path_for_Data):\n",
    "        os.mkdir(path_for_Data) \n",
    "    path_for_Data1 = os.path.join(path_for_Data,Creating_path2) # we are joining the old with new value to form a new path \n",
    "    if not os.path.exists(path_for_Data1):\n",
    "        os.mkdir(path_for_Data1) \n",
    "    path_for_name_notin = \"Album_Not_In_Spotify\"    \n",
    "    path_for_name_notin_sporify = os.path.join(path_for_Data,path_for_name_notin) # we are joining the old with new value to form a new path \n",
    "    if not os.path.exists(path_for_name_notin_sporify):\n",
    "        os.mkdir(path_for_name_notin_sporify) \n",
    "    spofiy_csv_file_name  =\"Albums_Not_In_Spotify.csv\"\n",
    "    spofiy_csv_file_for_notin_name = os.path.join(path_for_name_notin_sporify,spofiy_csv_file_name)\n",
    "    with open (spofiy_csv_file_for_notin_name,'a+') as outputfile1:\n",
    "            outputfile1.write(\"Album_Not_In_Spotify\"+\"\\n\")\n",
    "\n",
    "\n",
    "  \n",
    "    \n",
    "        \n",
    "    config = SafeConfigParser()\n",
    "    script_dir = os.getcwd()\n",
    "    config_file = os.path.join(script_dir, 'config\\config.cfg')\n",
    "    config.read(config_file)\n",
    "    \n",
    "    json_file_path = config.get('files','json_folder')\n",
    "    log_file = config.get('files','logfile')\n",
    "    \n",
    "    api_key = config.get('nytimes','api_key')    \n",
    "    query = config.get('nytimes','query')\n",
    "        \n",
    "    logging.basicConfig(filename=log_file, level=logging.INFO)\n",
    "    \n",
    "    logging.info(\"Getting started.\") \n",
    "    try:\n",
    "          getingArticles( query, api_key,path_for_Data1,spofiy_csv_file_for_notin_name,Todaydate) # calling another function\n",
    "\n",
    "    except:\n",
    "        logging.error(\"Unexpected error: %s\", str(sys.exc_info()[0]))\n",
    "    finally:\n",
    "        logging.info(\"Finished.\")\n",
    "\n",
    "    \n",
    "if __name__ == '__main__' :\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
