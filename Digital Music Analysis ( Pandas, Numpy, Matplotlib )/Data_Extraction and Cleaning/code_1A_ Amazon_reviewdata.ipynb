{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we are importing necessary package \n",
    "import os \n",
    "import pandas as pd \n",
    "import gzip \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# we are find the root of the directory on which the python is running \n",
    "Root_path=os.getcwd()\n",
    "Creating_path1=\"Data\"\n",
    "\n",
    "path_toread_Data = os.path.join(Root_path,Creating_path1) # we are joining the old with new value to form a new path \n",
    "if not os.path.exists(path_toread_Data):\n",
    "    os.mkdir(path_toread_Data)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# we rae writimg a function to open the meta data file \n",
    "lo=[]\n",
    "def parse(path): \n",
    "    g = gzip.open(path, 'rb') \n",
    "    for l in g: \n",
    "        yield eval(l)\n",
    "\n",
    "def getDF(path): \n",
    "    i = 0 \n",
    "    df = {} \n",
    "    for d in parse(path): \n",
    "        df[i] = d \n",
    "        i += 1 \n",
    "        lo.append(df)\n",
    "\n",
    "\n",
    "df = getDF('meta_Digital_Music.json.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# we are creating a emply list \n",
    "ALL_ASIN=[]\n",
    "ALL_TITLE=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# we are looping thri the json to get the data and appending it to a list \n",
    "ASIN=[]\n",
    "\n",
    "TITLE=[]\n",
    "DESCRIPTION=[]\n",
    "PRICE=[]\n",
    "CATEGORIES=[]\n",
    "URL=[]\n",
    "for i in range(0,279899):\n",
    "    d =lo[0][i]\n",
    "    asin= d.get(\"asin\",\"NULL\")\n",
    "    asin = str(asin)\n",
    "    asin = asin.replace('\\n','') # we are cleaning the data by replacong it with empty string  \n",
    "    asin = asin.replace(\",\",\"\")\n",
    "    asin = \"'\"+str(asin)\n",
    "    ASIN.append(asin)\n",
    "    ALL_ASIN.append(asin)\n",
    "\n",
    "    title= d.get(\"title\",\"NULL\")\n",
    "    title = str(title)\n",
    "    title = title.replace('\\n','') # we are cleaning the data by replacong it with empty string  \n",
    "    title = title.replace(\",\",\"\")\n",
    "    TITLE.append(title)\n",
    "    ALL_TITLE.append(title)\n",
    "\n",
    "    description= d.get(\"description\",\"NULL\")\n",
    "    description = str(description)\n",
    "    description = description.replace('\\n','') # we are cleaning the data by replacong it with empty string  \n",
    "    description = description.replace(\",\",\"\")\n",
    "    DESCRIPTION.append(description)\n",
    "    \n",
    "    price= d.get(\"price\", \"0\")\n",
    "    price = str(price)\n",
    "    price = price.replace('\\n','') # we are cleaning the data by replacong it with empty string  \n",
    "    price = price.replace(\",\",\"\")\n",
    "    PRICE.append(price)\n",
    "    \n",
    "    categories= d.get(\"categories\", \"NULL\")\n",
    "    categories = str(categories)\n",
    "    categories = categories.replace('\\n','') # we are cleaning the data by replacong it with empty string  \n",
    "    categories = categories.replace('[','') # we are cleaning the data by replacong it with empty string  \n",
    "    categories = categories.replace(']','') # we are cleaning the data by replacong it with empty string  \n",
    "    categories = categories.replace(\"'\",'') # we are cleaning the data by replacong it with empty string  \n",
    "    categories = categories.replace(\",\",\"\")\n",
    "    CATEGORIES.append(categories)\n",
    "    \n",
    "    imUrl= d.get(\"imUrl\",\"NULL\")\n",
    "    imUrl = str(imUrl)\n",
    "    imUrl = imUrl.replace(\",\",\"\")\n",
    "    URL.append(imUrl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we are creating a dataframe \n",
    "D1= pd.DataFrame(ASIN, columns=[\"ASIN\"])\n",
    "D2= pd.DataFrame(TITLE, columns=[\"TITLE\"])\n",
    "D3= pd.DataFrame(DESCRIPTION, columns=[\"DESCRIPTION\"])\n",
    "D4= pd.DataFrame(PRICE, columns=[\"PRICE\"])\n",
    "D5= pd.DataFrame(CATEGORIES, columns=[\"CATEGORIES\"])\n",
    "\n",
    "D6= pd.DataFrame(URL, columns=[\"URL\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "FINAL_DATA= pd.concat([D1, D2,D3,D4,D5,D6], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ASIN</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "      <th>PRICE</th>\n",
       "      <th>CATEGORIES</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'5555991584</td>\n",
       "      <td>Memory of Trees</td>\n",
       "      <td>NULL</td>\n",
       "      <td>9.49</td>\n",
       "      <td>CDs &amp; Vinyl New Age Celtic New Age CDs &amp; Vinyl...</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/51b5WDjd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'6308051551</td>\n",
       "      <td>Don't Drink His Blood</td>\n",
       "      <td>NEW Combo BLUWAVS CD and FLAC FILE</td>\n",
       "      <td>8.91</td>\n",
       "      <td>Digital Music Alternative Rock Indie &amp; Lo-Fi</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/31LT2n7Q...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ASIN                  TITLE                         DESCRIPTION  \\\n",
       "0  '5555991584        Memory of Trees                                NULL   \n",
       "1  '6308051551  Don't Drink His Blood  NEW Combo BLUWAVS CD and FLAC FILE   \n",
       "\n",
       "  PRICE                                         CATEGORIES  \\\n",
       "0  9.49  CDs & Vinyl New Age Celtic New Age CDs & Vinyl...   \n",
       "1  8.91       Digital Music Alternative Rock Indie & Lo-Fi   \n",
       "\n",
       "                                                 URL  \n",
       "0  http://ecx.images-amazon.com/images/I/51b5WDjd...  \n",
       "1  http://ecx.images-amazon.com/images/I/31LT2n7Q...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FINAL_DATA.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creating a directiory \n",
    "Amazon_processed_large_Data_csv =\"Amazon_Processed_Large_Data_csv\"\n",
    "\n",
    "path_toread_Data2 = os.path.join(path_toread_Data,Amazon_processed_large_Data_csv) # we are joining the old with new value to form a new path \n",
    "if not os.path.exists(path_toread_Data2):\n",
    "    os.mkdir(path_toread_Data2) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# creating a directiory and writing the file \n",
    "METADATA_MUSIC_ALL_DATA = \"METADATA_MUSIC_ALL_DATA.csv\"\n",
    "Amazon_METADATA_MUSIC_ALL_Data_csv_tobe_writen= os.path.join(path_toread_Data2,METADATA_MUSIC_ALL_DATA)\n",
    "\n",
    "with open (Amazon_METADATA_MUSIC_ALL_Data_csv_tobe_writen,'a+') as outputfile1:\n",
    "    outputfile1.write(FINAL_DATA.to_csv(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we are creating a dataframe \n",
    "D7= pd.DataFrame(ALL_ASIN, columns=[\"ALL_ASIN\"])\n",
    "D8= pd.DataFrame(ALL_TITLE, columns=[\"ALL_TITLE\"])\n",
    "FINAL_DATA_ALL_ASIN_TITLE= pd.concat([D7, D8], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creating a directiory and writing the file \n",
    "METADATA_MUSIC_ALL_ASIN_TITLE = \"METADATA_MUSIC_ALL_ASIN_TITLE.csv\"\n",
    "Amazon_METADATA_MUSIC_ALL_ASIN_TITLE_Data_csv_tobe_writen= os.path.join(path_toread_Data2,METADATA_MUSIC_ALL_ASIN_TITLE)\n",
    "\n",
    "with open (Amazon_METADATA_MUSIC_ALL_ASIN_TITLE_Data_csv_tobe_writen,'a+') as outputfile1:\n",
    "    outputfile1.write(FINAL_DATA_ALL_ASIN_TITLE.to_csv(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALL_ASIN</th>\n",
       "      <th>ALL_TITLE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'5555991584</td>\n",
       "      <td>Memory of Trees</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'6308051551</td>\n",
       "      <td>Don't Drink His Blood</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ALL_ASIN              ALL_TITLE\n",
       "0  '5555991584        Memory of Trees\n",
       "1  '6308051551  Don't Drink His Blood"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FINAL_DATA_ALL_ASIN_TITLE.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:1: FutureWarning: the take_last=True keyword is deprecated, use keep='last' instead\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "#Removing the dupliacte data\n",
    "Removing_Dupilcate_Title = FINAL_DATA_ALL_ASIN_TITLE.drop_duplicates('ALL_TITLE', take_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALL_ASIN</th>\n",
       "      <th>ALL_TITLE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'5555991584</td>\n",
       "      <td>Memory of Trees</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'6308051551</td>\n",
       "      <td>Don't Drink His Blood</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ALL_ASIN              ALL_TITLE\n",
       "0  '5555991584        Memory of Trees\n",
       "1  '6308051551  Don't Drink His Blood"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Removing_Dupilcate_Title.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creating a directiory and writing the file \n",
    "\n",
    "METADATA_MUSIC_REMOVED_DUPLICATE_TITLE_UPPERCASE = \"METADATA_MUSIC_REMOVED_DUPLICATE_TITLE_UPPERCASE.csv\"\n",
    "Amazon_METADATA_MUSIC_REMOVED_DUPLICATE_TITLE_UPPERCASE_csv_tobe_writen= os.path.join(path_toread_Data2,METADATA_MUSIC_REMOVED_DUPLICATE_TITLE_UPPERCASE)\n",
    "\n",
    "with open (Amazon_METADATA_MUSIC_REMOVED_DUPLICATE_TITLE_UPPERCASE_csv_tobe_writen,'a+') as outputfile1:\n",
    "    outputfile1.write(Removing_Dupilcate_Title.to_csv(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "Removing_Dupilcate_Title[\"ALL_TITLE\"] = Removing_Dupilcate_Title[\"ALL_TITLE\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALL_ASIN</th>\n",
       "      <th>ALL_TITLE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'5555991584</td>\n",
       "      <td>memory of trees</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'6308051551</td>\n",
       "      <td>don't drink his blood</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ALL_ASIN              ALL_TITLE\n",
       "0  '5555991584        memory of trees\n",
       "1  '6308051551  don't drink his blood"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Removing_Dupilcate_Title.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creating a directiory and writing the file \n",
    "\n",
    "METADATA_MUSIC_REMOVED_DUPLICATE_TITLE_LOWER = \"METADATA_MUSIC_REMOVED_DUPLICATE_TITLE_LOWER.csv\"\n",
    "Amazon_METADATA_MUSIC_REMOVED_DUPLICATE_TITLE_LOWER_csv_tobe_writen= os.path.join(path_toread_Data2,METADATA_MUSIC_REMOVED_DUPLICATE_TITLE_LOWER)\n",
    "\n",
    "with open (Amazon_METADATA_MUSIC_REMOVED_DUPLICATE_TITLE_LOWER_csv_tobe_writen,'a+') as outputfile1:\n",
    "    outputfile1.write(Removing_Dupilcate_Title.to_csv(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Justlower_title=Removing_Dupilcate_Title[\"ALL_TITLE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " # creating a directiory and writing the file \n",
    "  \n",
    "\n",
    "Amazon_Spotify_Just_Name_Lowercase_csv =\"Amazon_Spotify_Just_Name_Lowercase_csv\"\n",
    "path_toread_Data3 = os.path.join(path_toread_Data,Amazon_Spotify_Just_Name_Lowercase_csv) # we are joining the old with new value to form a new path \n",
    "if not os.path.exists(path_toread_Data3):\n",
    "    os.mkdir(path_toread_Data3) \n",
    "\n",
    "\n",
    "METADATA_Just_TITLE_LOWER = \"AMAZON_SPOTIFY_JUST_TITLE_LOWER.csv\"\n",
    "Amazon_Spotify_processed__Data_csv_tobe_writen= os.path.join(path_toread_Data3,METADATA_Just_TITLE_LOWER)\n",
    "\n",
    "with open (Amazon_Spotify_processed__Data_csv_tobe_writen,'a+') as outputfile1:\n",
    "    outputfile1.write(Justlower_title.to_csv(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
