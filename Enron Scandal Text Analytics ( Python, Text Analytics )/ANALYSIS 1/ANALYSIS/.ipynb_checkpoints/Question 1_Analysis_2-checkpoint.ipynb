{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Analysis _ 2 \n",
    "    \n",
    "    -Finding 1 \n",
    "\n",
    "        - we are trying to analyze the most occuring word in the subject of the sent email \n",
    "        - We are trying to generate the data dynamicaly by give range for year, day, month rather than finding the \n",
    "           value for a particular year, day, month . \n",
    "\n",
    "    -Finding 2 \n",
    "\n",
    "        - We are trying to find the email which was forwarded many times by taking the occurance of each subject   \n",
    "        - We are trying to generate the data dynamicaly by give range for year, day, month rather than finding the \n",
    "           value for a particular year, day, month . \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We are importing tokenize from nltk package \n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131072"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We are importing the CSV file and setting the limit \n",
    "import csv\n",
    "csv.field_size_limit(399999991)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#We importing the necessary package \n",
    "import glob\n",
    "import os\n",
    "from nltk.corpus import stopwords# We are importing the stopwords file package from nltk\n",
    "from operator import itemgetter # Importing the itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#We are defining the empty list and dictionary \n",
    "emailfromlist=[]\n",
    "emailtolist =[]\n",
    "emailfromdic={}\n",
    "emailtodic={}\n",
    "subjects=[]\n",
    "updated=[]\n",
    "subjectdic = {}\n",
    "justwords=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#We are defining the filepath \n",
    "filepath= os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E:\\\\NEU_MIS\\\\Spring_2016\\\\PYTHON\\\\Assignment_GitHub\\\\sekar_venkateshbabu_2017\\\\MIDTERM_FINAL\\\\QUESTION 1\\\\ANALYSIS'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#we are defining  the main funtion whic will perform the operation \n",
    "def mainmet(ys,ye,ms,me,ds,de):\n",
    "    for names in glob.glob(filepath):# using glob to scan the directory \n",
    "        with open('All_Content_file_sent_Email.csv','r') as csvfile:\n",
    "            reader = csv.reader(csvfile)# reading the csv \n",
    "            month= list (range(ms,me)) # creating the list to find the range \n",
    "            days= list (range(ds,de)) # creating the list to find the range \n",
    "            years= list(range(ys,ye)) # creating the list to find the range \n",
    "            for row in reader:# looping all the row to check the condition\n",
    "                for m in month:\n",
    "                    m1 = str(m)# covering the value to string \n",
    "                    m2 = str (row[3])# covering the value to string \n",
    "                    if m1 == m2: \n",
    "                        for d in days:\n",
    "                            d1 = str(d)# covering the value to string \n",
    "                            d2 = str (row[4])# covering the value to string \n",
    "                            if d1 == d2:\n",
    "                                for y in years:\n",
    "                                    y1 = str(y)# covering the value to string \n",
    "                                    y2 = str (row[2])# covering the value to string \n",
    "                                    if y1 == y2:\n",
    "                                        subjects.append(row[7])# Appending the value to teh list \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#we are calling the main funtion , the value can be changed dynamically \n",
    "mainmet(2001,2002,1,6,1,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We are cleaing the data in this loop \n",
    "for item in subjects:\n",
    "    if item !=\"\":\n",
    "        lower = item.lower()\n",
    "        items = lower.replace(\"re:\",\"\")# we are cleaning the data \n",
    "        items = items.replace(\"fw:\",\"\")# we are cleaning the data \n",
    "        updated.append(items)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We are using word_tokenize to tokenize the words\n",
    "for sentence in updated:\n",
    "    justwords.extend(word_tokenize(sentence))# we are tokenizing the words \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stop=stopwords.words('english')# We are using the stop words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We are cleaing the data and adding it to the dictionary in this loop \n",
    "for word in justwords: \n",
    "    if word.isalpha() and word not in stop: # checking if the alphabet is not in the stop list \n",
    "            \n",
    "        if word not in subjectdic:\n",
    "            subjectdic[word] = 1   # Adding to the dictionary if the words are not present \n",
    "        else:\n",
    "            subjectdic[word] += 1  # incrementing the count if the are present in the  dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subjectword = sorted(subjectdic.items(), key=itemgetter(1),reverse=True) \n",
    "# using the item getter to sort the dictionary based on the value in descending order "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 10 most words that are occuring in the sent email  \n",
      "  [('enron', 25), ('tonight', 17), ('power', 15), ('gas', 14), ('new', 12), ('meeting', 11), ('report', 10), ('front', 10), ('porch', 10), ('request', 8)]\n"
     ]
    }
   ],
   "source": [
    "# Printing top 10 most frequent words and their frequency\n",
    "print(\"The top 10 most words that are occuring in the sent email  \\n \",subjectword[:10] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open (\"Analysis2_part1.csv\",'a+') as outputfile1:\n",
    "    outputfile1.write(\"The top 10 most words that are occuring in the subject of the sent email are \\n\\n\\n\")\n",
    "    outputfile1.write(\"Most Words\"+\",\"+\"Frequency \"+\"\\n\")\n",
    "\n",
    "for i in range (0,10):\n",
    "    with open (\"Analysis2_part1.csv\",'a+') as outputfile1:\n",
    "        outputfile1.write(str(subjectword[i][0])+\",\"+str(subjectword[i][1])+\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We are finding the most same email has been sent based on the number of times the subject as been repeated  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We are adding the value to the dictionary based on few condition \n",
    "nlysubjectdic = {}\n",
    "for sub in updated:\n",
    "    if sub !=\"\":\n",
    "        if sub not in nlysubjectdic:\n",
    "            nlysubjectdic[sub] = 1   # Adding to the dictionary if the words are not present \n",
    "        else:\n",
    "            nlysubjectdic[sub] += 1  # incrementing the count if the are present in the  dictionary \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "onlysubjectsen = sorted(nlysubjectdic.items(), key=itemgetter(1),reverse=True) \n",
    "# using the item getter to sort the dictionary based on the value in descending order "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the given period the top 10 most no of email sent  \n",
      "  [(' tonight - front porch', 10), (' this weekend', 7), ('  happy hour tonight', 7), ('grades', 4), (' ttc/atc with the attachment!!', 4), ('  rv: pull!', 4), (' midway/ft. pierce pricing', 3), ('  cooper would be a cozy fit at kansas - cbs sportsline', 3), (\" user id's needed\", 3), (' corporate responsibility task force information', 3)]\n"
     ]
    }
   ],
   "source": [
    "# Printing top 10 most frequent words and their frequency\n",
    "print(\"For the given period the top 10 most no of email sent  \\n \",onlysubjectsen[:10] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open (\"Analysis2_part2.csv\",'a+') as outputfile1:\n",
    "    outputfile1.write(\"For the given period the top 10 most no of email sent based on the subject are \\n\\n\\n\")\n",
    "    outputfile1.write(\"Email Subject\"+\",\"+\"Frequency \"+\"\\n\")\n",
    "\n",
    "for i in range (0,10):\n",
    "    with open (\"Analysis2_part2.csv\",'a+') as outputfile1:\n",
    "        outputfile1.write(str(onlysubjectsen[i][0])+\",\"+str(onlysubjectsen[i][1])+\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Conclusion \n",
    " - We have found out the list of most number of words used in the subject and which subject has be forwarded the most for the given time period \n",
    " \n",
    " # Further Analysis \n",
    "\n",
    "- Since we have the top list of most number of words used in the subject and which subject has be forwarded the most, we can start our investigation by analysisng those email. \n",
    "- We can dig deeper into those email and what they were talking about  .\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
